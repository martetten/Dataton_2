{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLji9o16uNoU"
   },
   "source": [
    "# –ü–∞—Ä—Ç–Ω–µ—Ä—Å–∫–∞—è –∑–∞–¥–∞—á–∞: —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745934978063,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "488q9BW7wgM8",
    "outputId": "a870e80f-c6ce-410a-e1de-116bbe0928ca"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import EarlyStoppingCallback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Nqe7Fp0uxJl"
   },
   "source": [
    "## 1. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4itzOJvuYbd"
   },
   "source": [
    "–¥–∞–Ω—ã 6 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (–∫–∞–∂–¥—ã–π –¥–∞—Ç–∞—Å–µ—Ç - –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å) + –æ–ø–∏—Å–∞–Ω–∏–µ\n",
    "\n",
    "—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ \"—Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞\", video2text [OCR], speech2text [ASR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 4144,
     "status": "ok",
     "timestamp": 1745934983818,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "iaDJdEqguPEu"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/1.csv')\n",
    "df2 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/2.csv')\n",
    "df3 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/3.csv')\n",
    "df4 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/4.csv')\n",
    "df5 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/5.csv')\n",
    "df6 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745936637489,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "NiUWxqOAy2X4"
   },
   "outputs": [],
   "source": [
    "df1['class'] = 1\n",
    "df2['class'] = 2\n",
    "df3['class'] = 3\n",
    "df4['class'] = 4\n",
    "df5['class'] = 5\n",
    "df6['class'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ä–µ–¥–Ω–∏–º –¥–∞–Ω–Ω—ã–µ –≤ –æ–±—â–∏–π general –¥–∞—Ç–∞—Ñ—Ä–µ–π–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745937296460,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "1XfaD3rvzFDp"
   },
   "outputs": [],
   "source": [
    "df_gen = pd.concat([df1, df2, df3, df4, df5, df6]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = []\n",
    "\n",
    "for i in range(len(df_gen)):\n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç—Ä–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª\n",
    "    combined = str(df_gen['doc_text'].iloc[i]) + ' ' + \\\n",
    "                   str(df_gen['image2text'].iloc[i]) + ' ' + \\\n",
    "                   str(df_gen['speech2text'].iloc[i])\n",
    "    combined_text.append(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['combined_text'] = combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_gen['combined_text']\n",
    "labels = df_gen['class'].values - 1  # BERT –æ–∂–∏–¥–∞–µ—Ç –∫–ª–∞—Å—Å—ã 0-5 –≤–º–µ—Å—Ç–æ 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "test_dataset = TextDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../models/rubert_SL_datathon\"  # –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}_tokenizer\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    accuracy = accuracy_score(p.label_ids, preds)\n",
    "    \n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞: —É—á–∏—Ç—ã–≤–∞–µ–º –≤—Ç–æ—Ä–æ–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(p.predictions), dim=-1)\n",
    "    top2_correct = 0\n",
    "    for prob, label in zip(probs, p.label_ids):\n",
    "        _, top2_idx = torch.topk(prob, k=2)\n",
    "        if label in top2_idx:\n",
    "            top2_correct += 1\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'top2_accuracy': top2_correct / len(p.label_ids)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 48:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.007300</td>\n",
       "      <td>0.965336</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.911164</td>\n",
       "      <td>0.665833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.513600</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.8328120930989583, metrics={'train_runtime': 2896.8755, 'train_samples_per_second': 4.971, 'train_steps_per_second': 0.621, 'total_flos': 473616908697600.0, 'train_loss': 0.8328120930989583, 'epoch': 3.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # –ü–∞–ø–∫–∞ –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞)\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    ")\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {'accuracy': accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: rubert_SL_datathon\n",
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: rubert_SL_datathon_tokenizer\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(f\"{output_dir}_tokenizer\")\n",
    "\n",
    "print(f\"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_dir}\")\n",
    "print(f\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_dir}_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–ª—é—Å—ã:\n",
    "- Accuracy —Ä–∞—Å—Ç—ë—Ç —Å 66.75% –¥–æ 67.33%\n",
    "- Training Loss —Å—Ç–∞–±–∏–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è (1.01 -> 0.51)\n",
    "\n",
    "–ú–∏–Ω—É—Å—ã:\n",
    "- Validation Loss —É–≤–µ–ª–∏—á–∏–ª—Å—è –Ω–∞ 3-–π —ç–ø–æ—Ö–µ (0.911 -> 0.980) - –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
    "- Accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∞ –≤—Å–µ–≥–æ –Ω–∞ 1% –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —ç–ø–æ—Ö–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_two_results(model, tokenizer, texts, threshold=0.75):\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫, –≥–¥–µ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç:\n",
    "    - [top_class] –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= threshold\n",
    "    - [top_class, second_class] –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < threshold\n",
    "    \"\"\"\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "    inputs = tokenizer(list(texts), truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    results = []\n",
    "    for prob in probs:\n",
    "        top2_probs, top2_indices = torch.topk(prob, k=2)\n",
    "        if top2_probs[0] >= threshold:\n",
    "            results.append([top2_indices[0].item() + 1])  # +1 —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –∫–ª–∞—Å—Å—ã 1-6\n",
    "        else:\n",
    "            results.append([top2_indices[0].item() + 1, top2_indices[1].item() + 1])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "test_texts_list = test_texts.tolist()\n",
    "predictions = predict_with_two_results(model, tokenizer, test_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–∫—Å—Ç: VladRadimov https://t.me/VladRadimov/950    –ù–∞–≤–µ—Ä–Ω...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 5 –∏ 3 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: 5 —Å–µ–Ω—Ç—è–±—Ä—è –≤ –ø—Ä–æ–∫–∞—Ç –≤—ã—Ö–æ–¥–∏—Ç –∫–∞—Ä—Ç–∏–Ω–∞ ¬´–õ–≥—É–Ω—å—è¬ª - –ø–æ–±...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 4 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –° –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–º, –¥–æ—Ä–æ–≥–∏–µ –Ω–∞—à–∏! –° –†–æ–∂–¥–µ—Å—Ç–≤–æ–ºü§ç  –ß–µ—Ä–µ–¥–∞ ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 2 –∏ 4 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: https://youtu.be/LI0qJ8HR1DI?si=WVcc4q1A96UPEm8S  ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 1 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –õ–æ–∫–æ–º–æ—Ç–∏–≤!!! –ù–∞–¥–æ –µ—â–µ –∑–∞–±–∏–≤–∞—Ç—å –∏ –≤—ã–∏–≥—Ä—ã–≤–∞—Ç—å!!! üí™ n...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 5 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: ¬´Comedy Club¬ª –≤ –ø—è—Ç–Ω–∏—Ü—É –≤ 21:00 –Ω–∞ –¢–ù–¢ 1 9 tht —Ç–∞ ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 6 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –ê–Ω–≥–ª–∏—è –≤ —Ñ–∏–Ω–∞–ª–µ —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–º—É, —á—Ç–æ –µ—ë –≤—á–µ—Ä–∞ –ø–æ–¥–¥–µ—Ä...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 5 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: kruginapole https://t.me/kruginapole/89218 nan –∂–∞—Ä...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 6 –∏ 2 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: zarubinreporter https://t.me/zarubinreporter/1990 ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 3 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –º–æ–π —É—Ç—Ä–µ–Ω–Ω–∏–π —à–æ–∫ –≤ –õ–æ–Ω–¥–æ–Ω–µ - –ø–æ—Ö–æ–¥ –Ω–∞ —Å—Ç–∞–¥–∏–æ–Ω–Ω—ã–π —Ç...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 5 –∏ 2 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 10 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "for i in range(10):\n",
    "    print(f\"–¢–µ–∫—Å—Ç: {test_texts_list[i][:50]}...\")\n",
    "    if len(predictions[i]) == 1:\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions[i][0]} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\")\n",
    "    else:\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predictions[i][0]} –∏ {predictions[i][1]} (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑–º–µ–Ω–∏–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    hidden_dropout_prob=0.2,    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º dropout\n",
    "    attention_probs_dropout_prob=0.2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # –ü–∞–ø–∫–∞ –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞)\n",
    "    num_train_epochs=4,                    # –£–≤–µ–ª–∏—á–∏–º –Ω–∞ 1 —ç–ø–æ—Ö—É\n",
    "    per_device_train_batch_size=16,        # –£–≤–µ–ª–∏—á–∏–º –±–∞—Ç—á –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å\n",
    "    learning_rate=3e-5,                    # –£–≤–µ–ª–∏—á–∏–º —Å 2e-5 –¥–æ 3e-5\n",
    "    warmup_steps=100,                      # –£–º–µ–Ω—å—à–∏–º –ø—Ä–æ–≥—Ä–µ–≤\n",
    "    weight_decay=0.05,                     # –î–æ–±–∞–≤–∏–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=30,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True                              # –í–∫–ª—é—á–∏–º (–µ—Å—Ç—å GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–±–∞–≤–∏–º –≤ —Ç—Ä–µ–π–Ω–µ—Ä –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–æ–≤–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –Ω–∞ –Ω–æ–≤–æ–π —ç–ø–æ—Ö–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —É—Ö—É–¥—à–∞—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 45:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.058100</td>\n",
       "      <td>1.002572</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.928600</td>\n",
       "      <td>0.920146</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.956555</td>\n",
       "      <td>0.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.959962</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.8716999212900798, metrics={'train_runtime': 2722.4814, 'train_samples_per_second': 7.052, 'train_steps_per_second': 0.441, 'total_flos': 631489211596800.0, 'train_loss': 0.8716999212900798, 'epoch': 4.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: rubert_SL_datathon\n",
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: rubert_SL_datathon_tokenizer\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(f\"{output_dir}_tokenizer\")\n",
    "\n",
    "print(f\"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_dir}\")\n",
    "print(f\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_dir}_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "test_texts_list = test_texts.tolist()\n",
    "predictions = predict_with_two_results(model, tokenizer, test_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–∫—Å—Ç: VladRadimov https://t.me/VladRadimov/950    –ù–∞–≤–µ—Ä–Ω...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 3 –∏ 5 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: 5 —Å–µ–Ω—Ç—è–±—Ä—è –≤ –ø—Ä–æ–∫–∞—Ç –≤—ã—Ö–æ–¥–∏—Ç –∫–∞—Ä—Ç–∏–Ω–∞ ¬´–õ–≥—É–Ω—å—è¬ª - –ø–æ–±...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 4 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –° –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–º, –¥–æ—Ä–æ–≥–∏–µ –Ω–∞—à–∏! –° –†–æ–∂–¥–µ—Å—Ç–≤–æ–ºü§ç  –ß–µ—Ä–µ–¥–∞ ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 2 –∏ 4 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: https://youtu.be/LI0qJ8HR1DI?si=WVcc4q1A96UPEm8S  ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 1 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –õ–æ–∫–æ–º–æ—Ç–∏–≤!!! –ù–∞–¥–æ –µ—â–µ –∑–∞–±–∏–≤–∞—Ç—å –∏ –≤—ã–∏–≥—Ä—ã–≤–∞—Ç—å!!! üí™ n...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 5 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: ¬´Comedy Club¬ª –≤ –ø—è—Ç–Ω–∏—Ü—É –≤ 21:00 –Ω–∞ –¢–ù–¢ 1 9 tht —Ç–∞ ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 6 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –ê–Ω–≥–ª–∏—è –≤ —Ñ–∏–Ω–∞–ª–µ —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–º—É, —á—Ç–æ –µ—ë –≤—á–µ—Ä–∞ –ø–æ–¥–¥–µ—Ä...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 5 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: kruginapole https://t.me/kruginapole/89218 nan –∂–∞—Ä...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 2 –∏ 6 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: zarubinreporter https://t.me/zarubinreporter/1990 ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 3 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –º–æ–π —É—Ç—Ä–µ–Ω–Ω–∏–π —à–æ–∫ –≤ –õ–æ–Ω–¥–æ–Ω–µ - –ø–æ—Ö–æ–¥ –Ω–∞ —Å—Ç–∞–¥–∏–æ–Ω–Ω—ã–π —Ç...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 2 –∏ 5 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 10 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "for i in range(10):\n",
    "    print(f\"–¢–µ–∫—Å—Ç: {test_texts_list[i][:50]}...\")\n",
    "    if len(predictions[i]) == 1:\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions[i][0]} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\")\n",
    "    else:\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predictions[i][0]} –∏ {predictions[i][1]} (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑–º–µ–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª–∞ —É–∂–µ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Ö—É–¥—à–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = model_dir / \"training_runs\" / f\"run_{datetime.now().strftime('%Y-%m-%d_%H-%M')}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # –ü–∞–ø–∫–∞ –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞)\n",
    "    report_to=\"tensorboard\",               # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ª–æ–≥–∏\n",
    "    logging_strategy=\"steps\",              # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø–æ —à–∞–≥–∞–º\n",
    "    logging_steps=50,                      # –ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    num_train_epochs=10,                   # –£–≤–µ–ª–∏—á–∏–º –¥–æ 10 —ç–ø–æ—Ö\n",
    "    per_device_train_batch_size=16,        # –£–≤–µ–ª–∏—á–∏–º –±–∞—Ç—á –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å\n",
    "    learning_rate=5e-6,                    # –£–º–µ–Ω—å—à–∞–µ–º learning rate\n",
    "    warmup_steps=100,                      # –£–º–µ–Ω—å—à–∏–º –ø—Ä–æ–≥—Ä–µ–≤\n",
    "    weight_decay=0.05,                     # –î–æ–±–∞–≤–∏–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,                # Accuracy —á–µ–º –≤—ã—à–µ —Ç–µ–º –ª—É—á—à–µ\n",
    "    fp16=True                              # –í–∫–ª—é—á–∏–º (–µ—Å—Ç—å GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=1,\n",
    "            early_stopping_threshold=0.01,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 600/3000 22:26 < 1:30:04, 0.44 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>1.071947</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>1.192976</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.32455564657847086, metrics={'train_runtime': 1349.0204, 'train_samples_per_second': 35.581, 'train_steps_per_second': 2.224, 'total_flos': 315744605798400.0, 'train_loss': 0.32455564657847086, 'epoch': 2.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è —É–∂–µ –Ω–∞ –≤—Ç–æ—Ä–æ–π —ç–ø–æ—Ö–µ (Validation Loss —É–≤–µ–ª–∏—á–∏–ª—Å—è —Å 1.089 –¥–æ 1.208 –ø—Ä–∏ (–Ω–µ–±–æ–ª—å—à–æ–π) —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏ Accuracy), —Ä–∞—Å—á–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_with_two_results(model, tokenizer, test_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–∫—Å—Ç:  –ú—ã —Å–Ω–æ–≤–∞ –∏–≥—Ä–∞–µ–º –≤ –ö—É–±–∫–µ –†–æ—Å—Å–∏–∏!  –ë—É–¥–µ—Ç –±–æ–ª—å—à–æ–π –ø—Ä...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 5 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –ß—Ç–æ —É–∂–µ —Å–¥–µ–ª–∞–ª –†—ç—Ç–∫–ª–∏—Ñ—Ñ –≤ –ú–Æ, —á–µ—Ç—ã—Ä–µ –Ω–æ–≤–∏—á–∫–∞ –Ω–∞ –ø—Ä...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 5 –∏ 3 (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –ü–µ—á–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ —Ç–æ–∂–µ –µ—Å—Ç—å‚Ä¶. –£—Ç—Ä–æ–º —è –ø—Ä–æ—Å–Ω—É–ª–∞—Å—å –±...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 2 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –û–û–û–û–ô! –Ø–†–°–ê–ë–ê–õ–¨! 2-1,   ...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 5 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n",
      "–¢–µ–∫—Å—Ç: –£ –ª—é–¥–µ–π —Ä–∞–∑–Ω—ã–µ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏, —Ä–∞–∑–Ω–∞—è...\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: 2 (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 5 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "for i in range(4, 9):\n",
    "    print(f\"–¢–µ–∫—Å—Ç: {test_texts_list[i][:50]}...\")\n",
    "    if len(predictions[i]) == 1:\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions[i][0]} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 75%)\")\n",
    "    else:\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predictions[i][0]} –∏ {predictions[i][1]} (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPEVahx0fIW383Uz2UoYEaZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

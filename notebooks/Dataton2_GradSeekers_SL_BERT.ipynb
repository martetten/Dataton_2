{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLji9o16uNoU"
   },
   "source": [
    "# Партнерская задача: тематическая классификация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745934978063,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "488q9BW7wgM8",
    "outputId": "a870e80f-c6ce-410a-e1de-116bbe0928ca"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import EarlyStoppingCallback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Nqe7Fp0uxJl"
   },
   "source": [
    "## 1. Исследование датасета и предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4itzOJvuYbd"
   },
   "source": [
    "даны 6 датасетов (каждый датасет - отдельный класс) + описание\n",
    "\n",
    "разделение \"текст поста\", video2text [OCR], speech2text [ASR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 4144,
     "status": "ok",
     "timestamp": 1745934983818,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "iaDJdEqguPEu"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/1.csv')\n",
    "df2 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/2.csv')\n",
    "df3 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/3.csv')\n",
    "df4 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/4.csv')\n",
    "df5 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/5.csv')\n",
    "df6 = pd.read_csv('https://github.com/martetten/Dataton_2/raw/main/data/raw/6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745936637489,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "NiUWxqOAy2X4"
   },
   "outputs": [],
   "source": [
    "df1['class'] = 1\n",
    "df2['class'] = 2\n",
    "df3['class'] = 3\n",
    "df4['class'] = 4\n",
    "df5['class'] = 5\n",
    "df6['class'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объедним данные в общий general датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745937296460,
     "user": {
      "displayName": "A Martynov",
      "userId": "06661356698018382046"
     },
     "user_tz": -180
    },
    "id": "1XfaD3rvzFDp"
   },
   "outputs": [],
   "source": [
    "df_gen = pd.concat([df1, df2, df3, df4, df5, df6]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = []\n",
    "\n",
    "for i in range(len(df_gen)):\n",
    "    # Объединяем значения из трех столбцов через пробел\n",
    "    combined = str(df_gen['doc_text'].iloc[i]) + ' ' + \\\n",
    "                   str(df_gen['image2text'].iloc[i]) + ' ' + \\\n",
    "                   str(df_gen['speech2text'].iloc[i])\n",
    "    combined_text.append(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['combined_text'] = combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_gen['combined_text']\n",
    "labels = df_gen['class'].values - 1  # BERT ожидает классы 0-5 вместо 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "test_dataset = TextDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../models/rubert_SL_datathon\"  # Основная папка для модели\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}_tokenizer\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    accuracy = accuracy_score(p.label_ids, preds)\n",
    "    \n",
    "    # Дополнительная метрика: учитываем второй вариант\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(p.predictions), dim=-1)\n",
    "    top2_correct = 0\n",
    "    for prob, label in zip(probs, p.label_ids):\n",
    "        _, top2_idx = torch.topk(prob, k=2)\n",
    "        if label in top2_idx:\n",
    "            top2_correct += 1\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'top2_accuracy': top2_correct / len(p.label_ids)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 48:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.007300</td>\n",
       "      <td>0.965336</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.911164</td>\n",
       "      <td>0.665833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.513600</td>\n",
       "      <td>0.980760</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.8328120930989583, metrics={'train_runtime': 2896.8755, 'train_samples_per_second': 4.971, 'train_steps_per_second': 0.621, 'total_flos': 473616908697600.0, 'train_loss': 0.8328120930989583, 'epoch': 3.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Параметры обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # Папка для чекпоинтов (будет создана)\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1,  # Сохранять только лучшую модель\n",
    ")\n",
    "\n",
    "# Метрика для оценки\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {'accuracy': accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "# Создание Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Запуск обучения\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в: rubert_SL_datathon\n",
      "Токенизатор сохранен в: rubert_SL_datathon_tokenizer\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(f\"{output_dir}_tokenizer\")\n",
    "\n",
    "print(f\"Модель сохранена в: {output_dir}\")\n",
    "print(f\"Токенизатор сохранен в: {output_dir}_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плюсы:\n",
    "- Accuracy растёт с 66.75% до 67.33%\n",
    "- Training Loss стабильно уменьшается (1.01 -> 0.51)\n",
    "\n",
    "Минусы:\n",
    "- Validation Loss увеличился на 3-й эпохе (0.911 -> 0.980) - признаки переобучения\n",
    "- Accuracy на валидации выросла всего на 1% на последней эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_two_results(model, tokenizer, texts, threshold=0.75):\n",
    "    \"\"\"Возвращает список, где каждый элемент:\n",
    "    - [top_class] если уверенность >= threshold\n",
    "    - [top_class, second_class] если уверенность < threshold\n",
    "    \"\"\"\n",
    "    # Токенизация\n",
    "    inputs = tokenizer(list(texts), truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
    "    \n",
    "    # Предсказание\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Обработка результатов\n",
    "    results = []\n",
    "    for prob in probs:\n",
    "        top2_probs, top2_indices = torch.topk(prob, k=2)\n",
    "        if top2_probs[0] >= threshold:\n",
    "            results.append([top2_indices[0].item() + 1])  # +1 чтобы вернуть классы 1-6\n",
    "        else:\n",
    "            results.append([top2_indices[0].item() + 1, top2_indices[1].item() + 1])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример предсказания на тестовых данных\n",
    "test_texts_list = test_texts.tolist()\n",
    "predictions = predict_with_two_results(model, tokenizer, test_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: VladRadimov https://t.me/VladRadimov/950    Наверн...\n",
      "Предсказания: 5 и 3 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: 5 сентября в прокат выходит картина «Лгунья» - поб...\n",
      "Предсказание: 4 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: С праздником, дорогие наши! С Рождеством🤍  Череда ...\n",
      "Предсказания: 2 и 4 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: https://youtu.be/LI0qJ8HR1DI?si=WVcc4q1A96UPEm8S  ...\n",
      "Предсказание: 1 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: Локомотив!!! Надо еще забивать и выигрывать!!! 💪 n...\n",
      "Предсказание: 5 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: «Comedy Club» в пятницу в 21:00 на ТНТ 1 9 tht та ...\n",
      "Предсказание: 6 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: Англия в финале только потому, что её вчера поддер...\n",
      "Предсказание: 5 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: kruginapole https://t.me/kruginapole/89218 nan жар...\n",
      "Предсказания: 6 и 2 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: zarubinreporter https://t.me/zarubinreporter/1990 ...\n",
      "Предсказание: 3 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: мой утренний шок в Лондоне - поход на стадионный т...\n",
      "Предсказания: 5 и 2 (низкая уверенность)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов для первых 10 примеров\n",
    "for i in range(10):\n",
    "    print(f\"Текст: {test_texts_list[i][:50]}...\")\n",
    "    if len(predictions[i]) == 1:\n",
    "        print(f\"Предсказание: {predictions[i][0]} (уверенность >= 75%)\")\n",
    "    else:\n",
    "        print(f\"Предсказания: {predictions[i][0]} и {predictions[i][1]} (низкая уверенность)\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    hidden_dropout_prob=0.2,    # Увеличиваем dropout\n",
    "    attention_probs_dropout_prob=0.2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # Папка для чекпоинтов (будет создана)\n",
    "    num_train_epochs=4,                    # Увеличим на 1 эпоху\n",
    "    per_device_train_batch_size=16,        # Увеличим батч если позволяет память\n",
    "    learning_rate=3e-5,                    # Увеличим с 2e-5 до 3e-5\n",
    "    warmup_steps=100,                      # Уменьшим прогрев\n",
    "    weight_decay=0.05,                     # Добавим регуляризацию\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=30,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True                              # Включим (есть GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в трейнер возможность новой остановки, в случае, если на новой эпохе показатели ухудшатся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 45:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.058100</td>\n",
       "      <td>1.002572</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.928600</td>\n",
       "      <td>0.920146</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.956555</td>\n",
       "      <td>0.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.959962</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.8716999212900798, metrics={'train_runtime': 2722.4814, 'train_samples_per_second': 7.052, 'train_steps_per_second': 0.441, 'total_flos': 631489211596800.0, 'train_loss': 0.8716999212900798, 'epoch': 4.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в: rubert_SL_datathon\n",
      "Токенизатор сохранен в: rubert_SL_datathon_tokenizer\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(f\"{output_dir}_tokenizer\")\n",
    "\n",
    "print(f\"Модель сохранена в: {output_dir}\")\n",
    "print(f\"Токенизатор сохранен в: {output_dir}_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример предсказания на тестовых данных\n",
    "test_texts_list = test_texts.tolist()\n",
    "predictions = predict_with_two_results(model, tokenizer, test_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: VladRadimov https://t.me/VladRadimov/950    Наверн...\n",
      "Предсказания: 3 и 5 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: 5 сентября в прокат выходит картина «Лгунья» - поб...\n",
      "Предсказание: 4 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: С праздником, дорогие наши! С Рождеством🤍  Череда ...\n",
      "Предсказания: 2 и 4 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: https://youtu.be/LI0qJ8HR1DI?si=WVcc4q1A96UPEm8S  ...\n",
      "Предсказание: 1 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: Локомотив!!! Надо еще забивать и выигрывать!!! 💪 n...\n",
      "Предсказание: 5 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: «Comedy Club» в пятницу в 21:00 на ТНТ 1 9 tht та ...\n",
      "Предсказание: 6 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: Англия в финале только потому, что её вчера поддер...\n",
      "Предсказание: 5 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: kruginapole https://t.me/kruginapole/89218 nan жар...\n",
      "Предсказания: 2 и 6 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: zarubinreporter https://t.me/zarubinreporter/1990 ...\n",
      "Предсказание: 3 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: мой утренний шок в Лондоне - поход на стадионный т...\n",
      "Предсказания: 2 и 5 (низкая уверенность)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов для первых 10 примеров\n",
    "for i in range(10):\n",
    "    print(f\"Текст: {test_texts_list[i][:50]}...\")\n",
    "    if len(predictions[i]) == 1:\n",
    "        print(f\"Предсказание: {predictions[i][0]} (уверенность >= 75%)\")\n",
    "    else:\n",
    "        print(f\"Предсказания: {predictions[i][0]} и {predictions[i][1]} (низкая уверенность)\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим значение остановки, чтобы она происходила уже после первого ухудшения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = model_dir / \"training_runs\" / f\"run_{datetime.now().strftime('%Y-%m-%d_%H-%M')}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # Папка для чекпоинтов (будет создана)\n",
    "    report_to=\"tensorboard\",               # Автоматический логи\n",
    "    logging_strategy=\"steps\",              # Логировать по шагам\n",
    "    logging_steps=50,                      # Частота логирования\n",
    "    num_train_epochs=10,                   # Увеличим до 10 эпох\n",
    "    per_device_train_batch_size=16,        # Увеличим батч если позволяет память\n",
    "    learning_rate=5e-6,                    # Уменьшаем learning rate\n",
    "    warmup_steps=100,                      # Уменьшим прогрев\n",
    "    weight_decay=0.05,                     # Добавим регуляризацию\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,                # Accuracy чем выше тем лучше\n",
    "    fp16=True                              # Включим (есть GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=1,\n",
    "            early_stopping_threshold=0.01,  # Минимальное улучшение\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 600/3000 22:26 < 1:30:04, 0.44 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>1.071947</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>1.192976</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studies\\MEPhI_ML\\Dataton_2\\Dataton2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.32455564657847086, metrics={'train_runtime': 1349.0204, 'train_samples_per_second': 35.581, 'train_steps_per_second': 2.224, 'total_flos': 315744605798400.0, 'train_loss': 0.32455564657847086, 'epoch': 2.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты показывают, что модель начала переобучаться уже на второй эпохе (Validation Loss увеличился с 1.089 до 1.208 при (небольшой) стагнации Accuracy), расчет остановлен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_with_two_results(model, tokenizer, test_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст:  Мы снова играем в Кубке России!  Будет большой пр...\n",
      "Предсказание: 5 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: Что уже сделал Рэтклифф в МЮ, четыре новичка на пр...\n",
      "Предсказания: 5 и 3 (низкая уверенность)\n",
      "--------------------------------------------------\n",
      "Текст: Печальные новости тоже есть…. Утром я проснулась б...\n",
      "Предсказание: 2 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: ООООЙ! ЯРСАБАЛЬ! 2-1,   ...\n",
      "Предсказание: 5 (уверенность >= 75%)\n",
      "--------------------------------------------------\n",
      "Текст: У людей разные лингвистические способности, разная...\n",
      "Предсказание: 2 (уверенность >= 75%)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов для первых 5 примеров\n",
    "for i in range(4, 9):\n",
    "    print(f\"Текст: {test_texts_list[i][:50]}...\")\n",
    "    if len(predictions[i]) == 1:\n",
    "        print(f\"Предсказание: {predictions[i][0]} (уверенность >= 75%)\")\n",
    "    else:\n",
    "        print(f\"Предсказания: {predictions[i][0]} и {predictions[i][1]} (низкая уверенность)\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPEVahx0fIW383Uz2UoYEaZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
